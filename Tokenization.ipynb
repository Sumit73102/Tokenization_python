{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sumit73102/Tokenization_python/blob/main/Tokenization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Byte Pair Encoding Algorithm of Roberta-tokenizer"
      ],
      "metadata": {
        "id": "Nl9pYujEp87O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import RobertaTokenizer\n",
        "\n",
        "# Load RoBERTa tokenizer (uses Byte-level BPE)\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "\n",
        "text = \"He was walking around streets of Kalifornia.\"\n",
        "tokens = tokenizer.tokenize(text)\n",
        "token_ids = tokenizer.encode(text)\n",
        "\n",
        "print(\"Tokens:\", tokens)\n",
        "print(\"Token IDs:\", token_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5Fi3gLypvXe",
        "outputId": "e7eb27de-46a3-4760-d224-a63180e4aa43"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens: ['He', 'Ġwas', 'Ġwalking', 'Ġaround', 'Ġstreets', 'Ġof', 'ĠKal', 'if', 'ornia', '.']\n",
            "Token IDs: [0, 894, 21, 3051, 198, 2827, 9, 5507, 1594, 43052, 4, 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Byte Pair Encoding Algorithm for tokenization example (GPT-2)"
      ],
      "metadata": {
        "id": "M8CA8cdxpoBO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Tokenizer\n",
        "\n",
        "# Load a pretrained BPE tokenizer (GPT-2 uses BPE)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "\n",
        "# Input text\n",
        "text = \"He was walking around streets of Kalifornia.\"\n",
        "\n",
        "# Tokenize the text\n",
        "tokens = tokenizer.tokenize(text)\n",
        "token_ids = tokenizer.encode(text)\n",
        "\n",
        "# Decode to check reconstruction\n",
        "decoded = tokenizer.decode(token_ids)\n",
        "\n",
        "# Print results\n",
        "print(\"Token IDs:\", token_ids)\n",
        "print(\"Raw tokens:\", tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0gba1AipRLO",
        "outputId": "1132f5b7-35c2-4455-a25f-0ce7b39f4057"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token IDs: [1544, 373, 6155, 1088, 6483, 286, 12612, 361, 3317, 13]\n",
            "Raw tokens: ['He', 'Ġwas', 'Ġwalking', 'Ġaround', 'Ġstreets', 'Ġof', 'ĠKal', 'if', 'ornia', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word-piece algorithm for tokenization example (BERT)"
      ],
      "metadata": {
        "id": "1GtcHOf1o_zS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load pretrained WordPiece tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "\n",
        "# Tokenize some text\n",
        "text = \"He was walking around streets of Kalifornia.\"\n",
        "# Encode text\n",
        "input_ids = tokenizer.encode(text, add_special_tokens=True)\n",
        "\n",
        "# Output the token IDs\n",
        "print(\"Token IDs:\", input_ids)\n",
        "\n",
        "# Convert token IDs back to raw tokens and output them\n",
        "raw_tokens = [tokenizer.decode([token_id]) for token_id in input_ids]\n",
        "print(\"Raw tokens:\", raw_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7p-dQYYNo44j",
        "outputId": "d0c1564d-6180-44ff-c8d8-46ee16b60a47"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token IDs: [101, 1124, 1108, 3179, 1213, 4324, 1104, 22576, 14467, 4558, 1465, 119, 102]\n",
            "Raw tokens: ['[CLS]', 'He', 'was', 'walking', 'around', 'streets', 'of', 'Kali', '##fo', '##rn', '##ia', '.', '[SEP]']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Embedding Vector Generation for same word with different meanings"
      ],
      "metadata": {
        "id": "tXmtYhiBowSA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "\n",
        "# Load pre-trained BERT model and tokenizer\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Two sentences with the word \"bank\" having different meanings\n",
        "sentence1 = \"He deposited money in the bank.\"\n",
        "sentence2 = \"The boat reached the river bank.\"\n",
        "\n",
        "# Tokenize and convert to tensor\n",
        "inputs1 = tokenizer(sentence1, return_tensors='pt')\n",
        "inputs2 = tokenizer(sentence2, return_tensors='pt')\n",
        "print(\"Tokenization of input 1:\")\n",
        "print(inputs1.input_ids)\n",
        "tokens = tokenizer.convert_ids_to_tokens(inputs1[\"input_ids\"][0])\n",
        "print(tokens,\"\\n\")\n",
        "print(\"Tokenization of input 2:\")\n",
        "print(inputs2.input_ids)\n",
        "tokens = tokenizer.convert_ids_to_tokens(inputs2[\"input_ids\"][0])\n",
        "print(tokens,\"\\n\")\n",
        "# Generate embeddings\n",
        "with torch.no_grad():\n",
        "    outputs1 = model(**inputs1)\n",
        "    outputs2 = model(**inputs2)\n",
        "\n",
        "print(\"Dimension of Embedding matrix 1:\", outputs1.last_hidden_state[0].shape)\n",
        "print(\"Dimension of Embedding matrix 2:\", outputs2.last_hidden_state[0].shape)\n",
        "print(\"\\n\")\n",
        "# Extract the embeddings for the word \"bank\"\n",
        "bank_embedding1 = outputs1.last_hidden_state[0][5]  # Position of 'bank' in sentence 1\n",
        "bank_embedding2 = outputs2.last_hidden_state[0][5]  # Position of 'bank' in sentence 2\n",
        "\n",
        "print(\"Bank (Financial Institution) Embedding:\", bank_embedding1[:5])\n",
        "print(\"Bank (River) Embedding:\", bank_embedding2[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2DcVLBlnm5P",
        "outputId": "46d125cf-0252-4a37-8c42-08c7c3d76283"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenization of input 1:\n",
            "tensor([[  101,  2002, 14140,  2769,  1999,  1996,  2924,  1012,   102]])\n",
            "['[CLS]', 'he', 'deposited', 'money', 'in', 'the', 'bank', '.', '[SEP]'] \n",
            "\n",
            "Tokenization of input 2:\n",
            "tensor([[ 101, 1996, 4049, 2584, 1996, 2314, 2924, 1012,  102]])\n",
            "['[CLS]', 'the', 'boat', 'reached', 'the', 'river', 'bank', '.', '[SEP]'] \n",
            "\n",
            "Dimension of Embedding matrix 1: torch.Size([9, 768])\n",
            "Dimension of Embedding matrix 2: torch.Size([9, 768])\n",
            "\n",
            "\n",
            "Bank (Financial Institution) Embedding: tensor([ 0.5439, -0.3908, -0.3082,  0.3952,  0.3161])\n",
            "Bank (River) Embedding: tensor([ 0.4154,  0.1082, -0.3767,  0.1519,  0.4705])\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}